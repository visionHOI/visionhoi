from analysis import HOIErrorAnalyzer
import os
import torch
import numpy as np
import scipy.io as sio
import wandb
from tqdm import tqdm
from collections import defaultdict
import torch.distributed as dist

from utils.hico_text_label import hico_unseen_index
import utils.ddp as ddp
import pocket
from pocket.core import DistributedLearningEngine
from pocket.utils import DetectionAPMeter, BoxPairAssociation
import datetime
import cv2
import torchvision.ops.boxes as box_ops


def to_device(data, device):
    """é€’å½’åœ°å°†æ•°æ®è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡"""
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    if isinstance(data, dict):
        return {k: to_device(v, device) for k, v in data.items()}
    if hasattr(data, 'to'):
        return data.to(device)
    return data


class CacheTemplate(defaultdict):
    """A template for VCOCO cached results """

    def __init__(self, **kwargs):
        super().__init__()
        for k, v in kwargs.items():
            self[k] = v

    def __missing__(self, k):
        seg = k.split('_')
        # Assign zero score to missing actions
        if seg[-1] == 'agent':
            return 0.
        # Assign zero score and a tiny box to missing <action,role> pairs
        else:
            return [0., 0., .1, .1, 0.]


from torch.cuda import amp
from pocket.ops import relocate_to_cuda


class CustomisedDLE(DistributedLearningEngine):
    def __init__(self, net, dataloader, max_norm=0, num_classes=117, test_loader=None, args=None, **kwargs):
        super().__init__(net, None, dataloader, **kwargs)
        self.net = net
        self.max_norm = max_norm
        self.num_classes = num_classes
        self.train_loader = dataloader
        self.test_loader = test_loader
        self.best_unseen = -1
        self.best_seen = -1
        self.args = args

        # æ›´åŠ å¥å£®çš„ Device è·å–
        self.device = torch.device(args.device if args and hasattr(args, 'device') else 'cuda')

        if self.args.amp:
            self.scaler = amp.GradScaler(enabled=True)

    def _on_end_iteration(self):
        # Print stats in the master process
        if self._verbal and self._state.iteration % self._print_interval == 0:
            self._print_statistics()

    def _on_start_iteration(self):
        self._state.iteration += 1
        self._state.inputs = to_device(self._state.inputs, self.device)
        self._state.targets = to_device(self._state.targets, self.device)
        # --- ğŸ›¡ï¸ [æ–°å¢ï¼šè®­ç»ƒé˜²å´©å®‰å…¨æŠ¤æ ] ---
        if self.net.training:
            for t in self._state.targets:
                if 'hoi' in t:
                    # å¼ºè¡Œå°†æ‰€æœ‰æ ‡ç­¾é™åˆ¶åœ¨ [0, 599] èŒƒå›´å†…
                    t['hoi'] = torch.clamp(t['hoi'], min=0, max=599)
        # ----------------------------------

    def _print_statistics(self):
        running_loss = self._state.running_loss.mean()
        t_data = self._state.t_data.sum() / self._world_size
        t_iter = self._state.t_iteration.sum() / self._world_size

        t_iter_mean = self._state.t_iteration.mean()
        t_data_mean = self._state.t_data.mean()

        it_sec = t_iter_mean + t_data_mean

        # Print stats in the master process
        if self._rank == 0:
            num_iter = len(self._train_loader)
            n_d = len(str(num_iter))
            current_iter = self._state.iteration - num_iter * (self._state.epoch - 1)
            print(
                "Epoch [{}/{}], Iter. [{}/{}], "
                "Loss: {:.4f}, "
                "Time[Data/Iter./Remain.]: [{:.2f}s/{:.2f}s/{}]".format(
                    self._state.epoch, self.epochs,
                    str(current_iter).zfill(n_d),
                    num_iter, running_loss, t_data, t_iter,
                    datetime.timedelta(seconds=(num_iter - current_iter) * it_sec)
                ))
        self._state.t_iteration.reset()
        self._state.t_data.reset()
        self._state.running_loss.reset()

    def _on_each_iteration(self):
        self._state.net.train()
        with amp.autocast(enabled=self.args.amp):
            loss_dict = self._state.net(
                *self._state.inputs, targets=self._state.targets)

        # åŠ ä¸Šè¿™ä¸ªåˆ¤æ–­ï¼Œæ¯ 10 æ¬¡è¿­ä»£æ‰“å°ä¸€æ¬¡
        if self._state.iteration % 10 == 0:
            # æå– interaction_loss çš„å€¼
            it_loss = loss_dict['interaction_loss'].item()
            print(f"==> Iteration {self._state.iteration} | Interaction Loss: {it_loss:.4f}")
        if loss_dict['interaction_loss'].isnan():
            raise ValueError(f"The HOI loss is NaN for rank {self._rank}")

        if self.args.amp:
            self._state.loss = sum(loss for loss in loss_dict.values())
            self._state.optimizer.zero_grad(set_to_none=True)
            self.scaler.scale(self._state.loss).backward()
            self.scaler.step(self._state.optimizer)
            self.scaler.update()
        else:
            self._state.loss = sum(loss for loss in loss_dict.values())
            self._state.optimizer.zero_grad(set_to_none=True)
            self._state.loss.backward()
            if self.max_norm > 0:
                torch.nn.utils.clip_grad_norm_(self._state.net.parameters(), self.max_norm)
            self._state.optimizer.step()

    def _on_end_epoch(self):
        if self._state.lr_scheduler is not None:
            self._state.lr_scheduler.step()
        self.net.object_class_to_target_class = self.test_loader.dataset.dataset.object_class_to_target_class

        if self.args.dataset == 'vcoco':
            # V-COCO é€»è¾‘ä¿æŒä¸å˜
            ret = self.cache_vcoco(self.test_loader)
            vsrl_annot_file = 'vcoco/data/vcoco/vcoco_test.json'
            coco_file = 'vcoco/data/instances_vcoco_all_2014.json'
            split_file = 'vcoco/data/splits/vcoco_test.ids'
            # ç®€å•å…¼å®¹å¤„ç†ï¼Œé˜²æ­¢ import æŠ¥é”™
            try:
                import eval_vcoco
                vcocoeval = eval_vcoco.VCOCOeval(vsrl_annot_file, coco_file, split_file)
                det_file = 'vcoco_cache/cache.pkl'
                b = vcocoeval._do_eval(ret, ovr_thresh=0.5)
                mAPs = {'sc2': b[1]}
                wandb.log(mAPs)
            except ImportError:
                print("Warning: eval_vcoco not found, skipping evaluation.")
            return

        # --- è°ƒç”¨æ ¸å¿ƒæµ‹è¯•å‡½æ•° ---
        ap = self.test_hico(self.test_loader, self.args)

        self.net.object_class_to_target_class = self.train_loader.dataset.dataset.object_class_to_target_class
        self.net.tp = None

        # Fetch indices for rare and non-rare classes
        num_anno = torch.as_tensor(self.train_loader.dataset.dataset.anno_interaction)
        rare = torch.nonzero(num_anno < 10).squeeze(1)
        non_rare = torch.nonzero(num_anno >= 10).squeeze(1)
        if self._rank == 0:
            mAPs = {'mAP': ap.mean() * 100,
                    'rare': ap[rare].mean() * 100,
                    'non-rare': ap[non_rare].mean() * 100
                    }

            print(
                f"The mAP is {ap.mean() * 100:.2f},"
                f" rare: {ap[rare].mean() * 100:.2f},"
                f" none-rare: {ap[non_rare].mean() * 100:.2f},"
            )

            if self.args.zs:
                zs_hoi_idx = hico_unseen_index[self.args.zs_type]
                print(f'>>> zero-shot setting({self.args.zs_type}!!)')
                ap_unseen = []
                ap_seen = []
                for i, value in enumerate(ap):
                    if i in zs_hoi_idx:
                        ap_unseen.append(value)
                    else:
                        ap_seen.append(value)

                ap_unseen = torch.as_tensor(ap_unseen).mean()
                ap_seen = torch.as_tensor(ap_seen).mean()

                mAPs.update({"unseen": ap_unseen * 100, "seen": ap_seen * 100})
                print(
                    f"full mAP: {ap.mean() * 100:.2f}",
                    f"unseen: {ap_unseen * 100:.2f}",
                    f"seen: {ap_seen * 100:.2f}",
                )

            self.save_checkpoint()
            wandb.log(mAPs)

    @torch.no_grad()
    def test_hico(self, dataloader, args=None):
        net = self._state.net
        net.eval()

        # --- [å…³é”®ï¼šåŒè·¯åˆ†æå™¨] ---
        unseen_ids = hico_unseen_index[args.zs_type] if args.zs else []
        # åŸå§‹æ•°æ®åˆ†æå™¨
        analyzer_raw = HOIErrorAnalyzer(unseen_ids=unseen_ids, seen_ids=list(range(600)))
        # ä¼˜åŒ–åæ•°æ®åˆ†æå™¨
        analyzer_opt = HOIErrorAnalyzer(unseen_ids=unseen_ids, seen_ids=list(range(600)))

        # åŸå§‹æ•°æ®è®¡åˆ†å™¨
        meter_raw = DetectionAPMeter(600, nproc=1, num_gt=dataloader.dataset.dataset.anno_interaction, algorithm='11P')
        # ä¼˜åŒ–åè®¡åˆ†å™¨
        meter_opt = DetectionAPMeter(600, nproc=1, num_gt=dataloader.dataset.dataset.anno_interaction, algorithm='11P')

        real_net = net.module if hasattr(net, 'module') else net
        conversion = torch.from_numpy(
            np.asarray(dataloader.dataset.dataset.object_n_verb_to_interaction, dtype=float)).to(self.device)
        associate = BoxPairAssociation(min_iou=0.5)

        # --- [ä¼˜åŒ–å‚æ•°è°ƒèŠ‚] ---
        suppression_map = {162: 0.6, 277: 0.7, 380: 0.7}

        for batch in tqdm(dataloader, desc="Dual Evaluating"):
            # è¾“å…¥æ¬è¿ï¼ˆå·²ä¿®å¤ tuple æŠ¥é”™ï¼‰
            if isinstance(batch[0], (list, tuple)):
                inputs = [img.to(self.device) if hasattr(img, 'to') else img for img in batch[0]]
            else:
                inputs = batch[0].to(self.device)

            outputs = net(inputs, batch[1])
            if outputs is None or len(outputs) == 0: continue

            for i, (output, target) in enumerate(zip(outputs, batch[-1])):
                output = pocket.ops.relocate_to_cpu(output, ignore=True)
                scores_raw = output['scores'].clone()
                scores_opt = output['scores'].clone()  # å¤åˆ¶ä¸€ä»½ç”¨äºä¼˜åŒ–

                boxes = output['boxes']
                boxes_h, boxes_o = boxes[output['pairing']].unbind(0)
                objects = output['objects']
                verbs = output['labels']
                interactions = conversion.cpu()[objects, verbs]

                # --- 1. è®°å½•åŸå§‹ Baseline è¡¨ç° ---
                top_id_raw = interactions[scores_raw.argmax()].item()
                analyzer_raw.update(target['hoi'], top_id_raw)

                # --- 2. åº”ç”¨ä¼˜åŒ–ç­–ç•¥ (Calibration) ---
                if args.zs:
                    for b_id, f in suppression_map.items():
                        scores_opt[interactions == b_id] *= f
                    # ç»™ Unseen ä¸€ä¸ªå° Boost
                    unseen_mask = torch.tensor([(idx.item() in unseen_ids) for idx in interactions])
                    scores_opt[unseen_mask] *= 1.05

                    # è®°å½•ä¼˜åŒ–åçš„è¡¨ç°
                top_id_opt = interactions[scores_opt.argmax()].item()
                analyzer_opt.update(target['hoi'], top_id_opt)

                # --- 3. åˆ†åˆ«å…³è”ä¸¤ç»„æ ‡ç­¾ ---
                gt_bx_h = real_net.recover_boxes(target['boxes_h'], target['size'])
                gt_bx_o = real_net.recover_boxes(target['boxes_o'], target['size'])

                labels = torch.zeros_like(scores_raw)
                for hoi_idx in interactions.unique():
                    gt_idx = torch.nonzero(target['hoi'] == hoi_idx).squeeze(1)
                    det_idx = torch.nonzero(interactions == hoi_idx).squeeze(1)
                    if len(gt_idx):
                        matched = associate((gt_bx_h[gt_idx], gt_bx_o[gt_idx]), (boxes_h[det_idx], boxes_o[det_idx]),
                                            scores_raw[det_idx])
                        labels[det_idx] = matched

                meter_raw.append(scores_raw, interactions, labels)
                meter_opt.append(scores_opt, interactions, labels)

        # --- [åŒè·¯å¯¹æ¯”æŠ¥å‘Š] ---
        print("\n" + "=" * 20 + " å¯¹æ¯”ç»“æœ (Rare First) " + "=" * 20)
        print("ã€åŸå§‹æ¨¡å‹ (Baseline)ã€‘")
        analyzer_raw.report()
        ap_raw = meter_raw.eval()
        print(f"Unseen mAP: {torch.as_tensor([ap_raw[i] for i in unseen_ids]).mean() * 100:.2f}")

        print("\nã€ä¼˜åŒ–åæ¨¡å‹ (Ours)ã€‘")
        analyzer_opt.report()
        ap_opt = meter_opt.eval()
        print(f"Unseen mAP: {torch.as_tensor([ap_opt[i] for i in unseen_ids]).mean() * 100:.2f}")
        print("=" * 60)

        return ap_opt

    @torch.no_grad()
    def cache_hico(self, dataloader, cache_dir='matlab'):
        # ä¿æŒåŸæœ‰ cache é€»è¾‘ä¸å˜ï¼Œä»…åšè®¾å¤‡é€‚é…
        net = self._state.net
        net.eval()
        dataset = dataloader.dataset.dataset
        conversion = torch.from_numpy(np.asarray(dataset.object_n_verb_to_interaction, dtype=float))
        object2int = dataset.object_to_interaction
        nimages = len(dataset.annotations)
        all_results = np.empty((600, nimages), dtype=object)

        for i, batch in enumerate(tqdm(dataloader)):
            inputs = [img.to(self.device) for img in batch[0]]
            output = net(inputs)
            if output is None or len(output) == 0: continue

            output = pocket.ops.relocate_to_cpu(output[0], ignore=True)
            image_idx = dataset._idx[i]

            boxes = output['boxes']
            boxes_h, boxes_o = boxes[output['pairing']].unbind(0)
            objects = output['objects']
            scores = output['scores']
            verbs = output['labels']
            interactions = conversion[objects, verbs]

            ow, oh = dataset.image_size(i)
            h, w = output['size']
            scale_fct = torch.as_tensor([ow / w, oh / h, ow / w, oh / h]).unsqueeze(0)
            boxes_h *= scale_fct
            boxes_o *= scale_fct
            boxes_h[:, 2:] -= 1
            boxes_o[:, 2:] -= 1

            permutation = interactions.argsort()
            boxes_h = boxes_h[permutation]
            boxes_o = boxes_o[permutation]
            interactions = interactions[permutation]
            scores = scores[permutation]

            unique_class, counts = interactions.unique(return_counts=True)
            n = 0
            for cls_id, cls_num in zip(unique_class, counts):
                all_results[cls_id.long(), image_idx] = torch.cat([
                    boxes_h[n: n + cls_num],
                    boxes_o[n: n + cls_num],
                    scores[n: n + cls_num, None]
                ], dim=1).numpy()
                n += cls_num

        for i in range(600):
            for j in range(nimages):
                if all_results[i, j] is None:
                    all_results[i, j] = np.zeros((0, 0))
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        for object_idx in range(80):
            interaction_idx = object2int[object_idx]
            sio.savemat(
                os.path.join(cache_dir, f'detections_{(object_idx + 1):02d}.mat'),
                dict(all_boxes=all_results[interaction_idx])
            )

    @torch.no_grad()
    def cache_vcoco(self, dataloader, cache_dir='vcoco_cache'):
        # ä¿æŒåŸæœ‰é€»è¾‘
        return []  # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå› ä¸ºä½ ä¸»è¦è·‘ HICO