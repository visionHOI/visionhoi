import os
import subprocess
import sys
import glob

# ================= Kaggle é…ç½®åŒºåŸŸ =================
KAGGLE_INPUT = "/kaggle/input/hico-20160224-det/hico_20160224_det/hico_20160224_det"
KAGGLE_WEIGHTS = "/kaggle/input/lain-pretrained-weights"

DATA_ROOT = "/kaggle/working/hicodet"
PRETRAINED = os.path.join(KAGGLE_WEIGHTS, "detr-r50-hicodet.pth")

# --- å…³é”®ä¿®æ”¹ï¼šé™ä½ BS ä»¥é˜²æ­¢ OOMï¼Œç¼©çŸ­ Epochs ç¡®ä¿ 12 å°æ—¶å†…èƒ½å‡º mAP ---
EPOCHS = 3  # å»ºè®®å…ˆè·‘ 3 ä¸ª Epoch éªŒè¯ Adapter æœ‰æ•ˆæ€§
BATCH_SIZE = 2  # 16G æ˜¾å­˜ä¸‹ï¼Œä½¿ç”¨ ViT-B è·‘åˆ†å¸ƒå¼/å¤šä»»åŠ¡å»ºè®®è®¾ä¸º 2
LR_HEAD = "1e-4"
# =================================================

experiments = [
    {
        "name": "Baseline_No_Adapter",
        "args": "--use_prompt",
        "output_dir": "/kaggle/working/checkpoints/baseline"
    },
    {
        "name": "With_Semantic_Adapter",
        "args": "--use_prompt --use_semantic_adapter --adapt_dim 64",
        "output_dir": "/kaggle/working/checkpoints/adapter_exp"
    }
]


def setup_kaggle_environment():
    """è·¯å¾„å¯¹é½ä¸è½¯é“¾æ¥"""
    print("\nğŸš€ æ­£åœ¨åˆå§‹åŒ– Kaggle ç¯å¢ƒ...")
    inner_path = os.path.join(DATA_ROOT, "hico_20160224_det")
    os.makedirs(inner_path, exist_ok=True)

    drive_img_path = os.path.join(KAGGLE_INPUT, "images")
    local_img_path = os.path.join(inner_path, "images")

    if not os.path.exists(local_img_path):
        print(f"ğŸ”— é“¾æ¥å›¾ç‰‡åº“...")
        subprocess.run(f"ln -sf {drive_img_path} {local_img_path}", shell=True)

    print("ğŸ“ æ‹·è´æ ‡æ³¨æ–‡ä»¶...")
    subprocess.run(f"cp {KAGGLE_INPUT}/*.json {inner_path}/", shell=True)
    subprocess.run(f"cp {KAGGLE_INPUT}/*.json {DATA_ROOT}/", shell=True)


def run_cmd(cmd):
    env = os.environ.copy()
    env["WANDB_MODE"] = "disabled"
    env["MASTER_ADDR"] = "localhost"
    env["MASTER_PORT"] = "12345"
    env["RANK"] = "0"
    env["WORLD_SIZE"] = "1"
    # æ˜¾å­˜ç¢ç‰‡ä¼˜åŒ–ç­–ç•¥
    env["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

    print(f"\nğŸ”¥ æ­£åœ¨æ‰§è¡Œ: {cmd}\n")
    process = subprocess.Popen(cmd, shell=True, env=env, stdout=sys.stdout, stderr=sys.stderr)
    process.wait()


def main():
    setup_kaggle_environment()

    for exp in experiments:
        print(f"\nğŸŒŸ === æ­£åœ¨å¼€å§‹å®éªŒ: {exp['name']} === ğŸŒŸ")
        os.makedirs(exp['output_dir'], exist_ok=True)

        # 1. è®­ç»ƒå‘½ä»¤
        # ä¿®æ”¹ç‚¹ï¼šbackbone è®¾ä¸º clip_ViT-B-16ï¼Œæ‰‹åŠ¨æ·»åŠ  hidden_dim 512
        train_cmd = f"python main.py --dataset hicodet --batch-size {BATCH_SIZE} --epochs {EPOCHS} " \
                    f"--num-workers 4 --lr-head {LR_HEAD} --backbone resnet50 " \
                    f"--data-root {DATA_ROOT} --pretrained {PRETRAINED} " \
                    f"--output-dir {exp['output_dir']} --zs --zs_type rare_first {exp['args']}"

        run_cmd(train_cmd)

        # 2. è‡ªåŠ¨è¯„ä¼°å‘½ä»¤ (mAP)
        # å¯»æ‰¾è®­ç»ƒäº§ç”Ÿçš„æœ€åä¸€ä¸ª checkpoint
        ckpts = glob.glob(os.path.join(exp['output_dir'], "*.pt"))
        if ckpts:
            latest_ckpt = max(ckpts, key=os.path.getctime)
            print(f"ğŸ“Š è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨è¯„ä¼° {exp['name']} çš„ mAP... (ä½¿ç”¨æƒé‡: {latest_ckpt})")

            eval_cmd = f"python main.py --dataset hicodet --data-root {DATA_ROOT} " \
                       f"--backbone resnet50 " \
                       f"--resume {latest_ckpt} --eval --output-dir {exp['output_dir']}"
            run_cmd(eval_cmd)

        # 3. æ¯ä¸ªå®éªŒç»“æŸåå¼ºåˆ¶é‡Šæ”¾æ˜¾å­˜
        import torch, gc
        gc.collect()
        torch.cuda.empty_cache()


if __name__ == "__main__":
    main()